To guarantee comparability between the different models, we first split the utilization data into train, test and validation splits of 60%, 20%, 20% respectively using a common seed. After the split, data was normalized to values between 0 and 1, to improve stability of the machine learning models. As features for the predictive models, we used the hour, weekday and month of the utilization datapoint, as well as whether it is a holiday or not. We also used the temperature and precipitation from the weather dataset. The target variable is the utilization of the specific charging site. We explicitly decided to separate the sites and train individual models for each one. This is because, as we have seen in the descriptive data analysis, the sites differ greatly in their characteristics, e.g. in the variance within the data.
As our first predictive model, we decided to use a decision tree. We also tested linear regression as well as polynomial regression with L2 regularization. However, these performed significantly worse. As mentioned before, we trained two different models for the private and the public site. In principle, both are based on the same foundation. A decision tree regression with hyperparameter selection via GridSearch. In order to obtain the best possible models, we tested the use of different hyperparameters to control the complexity of the model and improve its results on performance measures. Figure X shows the decision trees resulting from the best hyperparameters for both sites. It is immediately apparent that the tree for the second site is slightly more complex. In addition, the performance of the RMSE and MSE performance measures is significantly better. In contrast, the result of the R2 score and the MAE is worse. This could only be increased slightly by adjusting the parameters but was accompanied by an enormous increase in complexity and thus a poorer generalization of the model.  However, regarding the domain and the inclusion of background knowledge about the data, it makes sense that the MAE is lower and R2 score is higher for the private site than for the public site. As already mentioned in the analysis, the variance within the private site is much smaller, as here, for example, the use of car parks follows regular working hours. This is not the case with the public site. To improve performance, ensemble methods such as random forests and bagging were also included and tested. However, this resulted in a limitation with regard to the hardware and the associated runtime due to the increased computational complexity. Ensemble methods with simpler hyperparameter settings, which also terminated in a reasonable time, did not lead to any visible improvement in terms of the performance measures. 
To compare our models, we mainly rely on the performance measures of mean absolute error and r^2. The mean absolute error in particular can be interpreted well with regard to the effects on utilization score we want to predict.Both models, the neural network and the decision tree, show a relatively similar performance in terms of mean absolute error. The decision tree performs slightly better on the private site, while the neural network performs slightly better on the public site. Nevertheless, both models are able to explain at least 87% of the variance of the data on the 
